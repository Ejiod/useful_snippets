import pyodbc
import pandas as pd

def create_table_and_insert_data(df, table_name, connection):
    # Start the CREATE MULTISET TABLE statement
    sql = f"CREATE MULTISET TABLE {table_name} ("
    # Add a column definition for each column in the DataFrame
    for col in df.columns:
        # Infer the Teradata data type from the DataFrame's data type
        if df[col].dtype == 'int64':
            teradata_type = 'INTEGER'
        elif df[col].dtype == 'float64':
            teradata_type = 'FLOAT'
        elif df[col].dtype == 'bool':
            teradata_type = 'BYTEINT'
        elif df[col].dtype == 'datetime64[ns]':
            teradata_type = 'TIMESTAMP'
        else:
            teradata_type = 'VARCHAR(255)'
        # Add the column definition to the SQL statement
        sql += f"\n    {col} {teradata_type},"
    # Remove the trailing comma and close the parenthesis
    sql = sql.rstrip(',') + "\n)"
    # Execute the CREATE TABLE statement
    connection.execute(sql)
    connection.commit()
    # Now, perform the bulk insert
    params = ','.join(['?'] * len(df.columns))
    for index, row in df.iterrows():
        connection.execute(f"INSERT INTO {table_name} VALUES ({params})", tuple(row))
    # Commit the transaction
    connection.commit()

def create_view(source_table, target_table, connection):
    sql = f"CREATE VIEW {source_table} AS SELECT * FROM {target_table}"
    connection.execute(sql)
    connection.commit()

def drop_table(table_name, connection):
    sql = f"DROP TABLE {table_name}"
    connection.execute(sql)
    connection.commit()

# Define the source and target table names
migration_df = pd.DataFrame({
    'source_db': ['TD500', 'TD500', 'TD500'],
    'target_db': ['TD800', 'TD800', 'TD800'],
    'source_table': ['tableA', 'tableB', 'tableC'],
    'target_table': ['tableA', 'tableB', 'tableC']
})

# Connect to the source and target servers
source_connection = pyodbc.connect('DSN=YourSourceDSN;UID=YourUsername;PWD=YourPassword')
target_connection = pyodbc.connect('DSN=YourTargetDSN;UID=YourUsername;PWD=YourPassword')

# Migrate each table, create a view, then drop the original table
for _, row in migration_df.iterrows():
    df = pd.read_sql(f"SELECT * FROM {row['source_table']}", source_connection)
    create_table_and_insert_data(df, row['target_table'], target_connection)
    create_view(row['source_table'], row['target_table'], source_connection)
    drop_table(row['source_table'], source_connection)
