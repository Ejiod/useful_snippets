CREATE OR REPLACE PROCEDURE clean_and_shift_addresses(table_name STRING)
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.8'
PACKAGES = ('snowflake-snowpark-python', 'regex')
HANDLER = 'clean_and_shift'
AS
$$
from snowflake.snowpark.functions import col, trim, when, lit, udf
from snowflake.snowpark.types import StringType, BooleanType
import regex as re

def clean_and_shift(session, table_name):
    # Define the UDF for postcode validation
    @udf(return_type=BooleanType(), input_types=[StringType()])
    def is_valid_uk_postcode(postcode: str) -> bool:
        pattern = r'^[A-Z]{1,2}[0-9][A-Z0-9]? ?[0-9][A-Z]{2}$'
        if postcode is None:
            return False
        return re.match(pattern, postcode.strip().upper()) is not None

    # Define the UDF for postcode formatting
    @udf(return_type=StringType(), input_types=[StringType()])
    def format_uk_postcode(postcode: str) -> str:
        if postcode is None:
            return None
        postcode = postcode.strip().upper()
        # Remove any existing spaces
        postcode = postcode.replace(" ", "")
        # Insert a space in the correct position
        if len(postcode) > 3:
            return postcode[:-3] + " " + postcode[-3:]
        return postcode

    # Get the table
    df = session.table(table_name)

    # Get all columns in their original order
    all_columns = df.columns

    # Strip spaces from all columns
    for column in all_columns:
        df = df.withColumn(column, trim(col(column)))

    # Identify address columns dynamically
    address_columns = [col_name for col_name in all_columns if re.search(r'(?i)address[ _]?line[0-9]*|add[ _]?line[0-9]*', col_name)]
    address_columns.sort()  # Ensure they are in the correct order

    # Shift address lines
    for i in range(len(address_columns) - 1):
        for j in range(i + 1, len(address_columns)):
            df = df.withColumn(
                address_columns[i],
                when((col(address_columns[i]) == '') & (col(address_columns[j]) != ''), 
                     col(address_columns[j]))
                .otherwise(col(address_columns[i]))
            )
            df = df.withColumn(
                address_columns[j],
                when((col(address_columns[i]) == col(address_columns[j])) & (col(address_columns[j]) != ''), 
                     lit(''))
                .otherwise(col(address_columns[j]))
            )

    # Identify postcode columns dynamically
    postcode_columns = [col_name for col_name in all_columns if re.search(r'(?i)post[ _]?code[0-9]*', col_name)]

    for postcode_column in postcode_columns:
        # Format postcodes
        df = df.withColumn(postcode_column, format_uk_postcode(col(postcode_column)))

        # Validate postcodes
        df = df.withColumn(f'IS_VALID_{postcode_column.upper()}', is_valid_uk_postcode(col(postcode_column)))

    # Identify customer ID columns dynamically
    customer_id_columns = [col_name for col_name in all_columns if re.search(r'(?i)customer[ _]?id|CIN', col_name)]
    
    # Check if there are any invalid postcodes
    invalid_postcodes = []
    for postcode_column in postcode_columns:
        invalid_postcodes.extend(df.filter(~col(f'IS_VALID_{postcode_column.upper()}')).collect())

    if invalid_postcodes:
        invalid_records = "Invalid postcodes found:\n"
        for row in invalid_postcodes:
            for postcode_column in postcode_columns:
                if not row[f'IS_VALID_{postcode_column.upper()}']:
                    for customer_id_column in customer_id_columns:
                        invalid_records += f"{customer_id_column}: {row[customer_id_column]}, {postcode_column}: {row[postcode_column]}\n"
        return invalid_records

    # If all postcodes are valid, remove the validation columns
    for postcode_column in postcode_columns:
        df = df.drop(f'IS_VALID_{postcode_column.upper()}')

    # Reorder columns to match original order
    df = df.select([col(c) for c in all_columns])

    # Overwrite the original table with the cleaned and shifted data without dropping the table
    temp_table_name = table_name + "_temp"
    df.write.mode("overwrite").save_as_table(temp_table_name)
    
    # Swap the temporary table with the original table to preserve the schema and other properties
    session.sql(f"ALTER TABLE {table_name} SWAP WITH {temp_table_name}").collect()

    return f"Successfully cleaned, shifted addresses, formatted and validated postcodes in {table_name}"
$$;
