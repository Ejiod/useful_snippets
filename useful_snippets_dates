import cx_Oracle
import pandas as pd

# Function to chunk a list into smaller lists of a specified size
def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

# Function to execute a chunked query and combine results
def execute_chunked_query(connection, acc_list, bn_list, table_name):
    cursor = connection.cursor()
    acc_chunks = list(chunk_list(acc_list, 1000))
    bn_chunks = list(chunk_list(bn_list, 1000))
    
    total_count = 0
    
    for acc_chunk in acc_chunks:
        for bn_chunk in bn_chunks:
            acc_placeholders = ','.join(':' + str(i + 1) for i in range(len(acc_chunk)))
            bn_placeholders = ','.join(':' + str(len(acc_chunk) + i + 1) for i in range(len(bn_chunk)))
            
            query = f"""
            SELECT COUNT(*) FROM {table_name}
            WHERE Acc IN ({acc_placeholders})
            AND Bn IN ({bn_placeholders})
            """
            
            params = acc_chunk + bn_chunk
            cursor.execute(query, params)
            
            count = cursor.fetchone()[0]
            total_count += count
    
    cursor.close()
    return total_count

# Provide your Oracle database connection details
dsn_tns = cx_Oracle.makedsn('host', 'port', service_name='service_name')
connection = cx_Oracle.connect(user='username', password='password', dsn=dsn_tns)

# Example DataFrame with more than 4000 entries
df = pd.DataFrame({
    'Acc': ['A1', 'A2', 'A3', ..., 'A4000'],
    'Bn': ['B1', 'B2', 'B3', ..., 'B4000']
})

# Extract unique values from DataFrame
acc_list = df['Acc'].unique().tolist()
bn_list = df['Bn'].unique().tolist()

# Table name
table_name = 'your_table_name'

# Execute the chunked query
total_count = execute_chunked_query(connection, acc_list, bn_list, table_name)

# Print the total count
print(f'Total count: {total_count}')

# Close the connection
connection.close()



import connectorx as cx
import pandas as pd

# Function to chunk a list into smaller lists of a specified size
def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

# Function to execute a chunked query and combine results
def execute_chunked_query(connection_str, acc_list, bn_list, table_name):
    acc_chunks = list(chunk_list(acc_list, 1000))
    bn_chunks = list(chunk_list(bn_list, 1000))
    
    total_count = 0
    
    for acc_chunk in acc_chunks:
        for bn_chunk in bn_chunks:
            acc_placeholders = ','.join(f"'{acc}'" for acc in acc_chunk)
            bn_placeholders = ','.join(f"'{bn}'" for bn in bn_chunk)
            
            query = f"""
            SELECT COUNT(*) AS cnt FROM {table_name}
            WHERE Acc IN ({acc_placeholders})
            AND Bn IN ({bn_placeholders})
            """
            
            df = cx.read_sql(connection_str, query)
            total_count += df['cnt'].sum()
    
    return total_count

# Example DataFrame with more than 4000 entries
df = pd.DataFrame({
    'Acc': [f'A{i}' for i in range(1, 4001)],
    'Bn': [f'B{i}' for i in range(1, 4001)]
})

# Extract unique values from DataFrame
acc_list = df['Acc'].unique().tolist()
bn_list = df['Bn'].unique().tolist()

# Connection string
connection_str = "oracle://username:password@host:port/service_name"

# Table name
table_name = 'your_table_name'

# Execute the chunked query
total_count = execute_chunked_query(connection_str, acc_list, bn_list, table_name)

# Print the total count
print(f'Total count: {total_count}')




import cx_Oracle
import pandas as pd

# Function to chunk a list into smaller lists of a specified size
def chunk_list(lst, chunk_size):
    for i in range(0, len(lst), chunk_size):
        yield lst[i:i + chunk_size]

# Function to execute a chunked query and combine results
def execute_chunked_query(connection, acc_bn_list, table_name):
    # Split acc_bn_list into chunks of 20
    acc_bn_chunks = list(chunk_list(acc_bn_list, 20))
    
    total_count = 0
    
    cursor = connection.cursor()
    
    for acc_bn_chunk in acc_bn_chunks:
        # Create a placeholder string for the IN clause
        acc_bn_placeholders = ','.join(f"'{acc_bn}'" for acc_bn in acc_bn_chunk)
        
        # Construct the SQL query
        query = f"""
        SELECT COUNT(*) AS cnt FROM {table_name}
        WHERE Acc || Bn IN ({acc_bn_placeholders})
        """
        
        # Execute the query
        cursor.execute(query)
        # Fetch the count result
        count = cursor.fetchone()[0]
        # Accumulate the count
        total_count += count
    
    cursor.close()
    
    return total_count

# Provide your Oracle database connection details
dsn_tns = cx_Oracle.makedsn('host', 'port', service_name='service_name')
connection = cx_Oracle.connect(user='username', password='password', dsn=dsn_tns)

# Example DataFrame with more than 4000 entries
df = pd.DataFrame({
    'Acc': [f'A{i}' for i in range(1, 4001)],
    'Bn': [f'B{i}' for i in range(1, 4001)]
})

# Concatenate Acc and Bn values
df['AccBn'] = df['Acc'] + df['Bn']
acc_bn_list = df['AccBn'].unique().tolist()

# Table name
table_name = 'your_table_name'

# Execute the chunked query
total_count = execute_chunked_query(connection, acc_bn_list, table_name)

# Print the total count
print(f'Total count: {total_count}')

# Close the connection
connection.close()

import pandas as pd
import connectorx as cx
import pyarrow.parquet as pq
import pyarrow as pa

# Define connection string and query
connection_string = "oracle://username:password@hostname:port/service_name"
table_name = "your_table"
chunk_size = 10000
offset = 0

# Function to fetch a chunk of data
def fetch_chunk(connection_string, table_name, chunk_size, offset):
    query = f"SELECT * FROM {table_name} OFFSET {offset} ROWS FETCH NEXT {chunk_size} ROWS ONLY"
    return cx.read_sql(connection_string, query)

# Loop to read chunks and write to Parquet
chunk_number = 0
while True:
    df = fetch_chunk(connection_string, table_name, chunk_size, offset)
    if df.empty:
        break

    # Convert DataFrame to Parquet
    table = pa.Table.from_pandas(df)
    pq.write_table(table, f'chunk_{chunk_number}.parquet')

    print(f'Exported chunk_{chunk_number}.parquet')

    chunk_number += 1
    offset += chunk_size

print("Export completed.")



